---
title: <center style="font-size:30px;font-style:normal;color:black;">Accompanying Code 02:</center>
subtitle: <center style="font-size:30px;font-style:normal;color:#0E0E7D;">SPCC Similarity and Preparing for Visual Classification</center>
 &nbsp;
author: |
  <center style="font-style:normal;">
  <a style="font-size:22px;color:#337ab7;text-decoration: underline;"href="http://smith-vidaurre.com/">Grace Smith-Vidaurre</a><sup><span style="font-size:12px;color:black;text-decoration:none!important;">1-4*</span></sup>
  &nbsp;
  <center style="font-size:18px;font-style:normal;color:black;"><sup><span style="font-size:12px;color:black;">1</span></sup>Department of Biology, New Mexico State University</center>
  <center style="font-size:18px;font-style:normal;color:black;"><sup><span style="font-size:12px;color:black;">2</span></sup>Laboratory of Neurogenetics of Language, Rockefeller University</center>
  <center style="font-size:18px;font-style:normal;color:black;"><sup><span style="font-size:12px;color:black;">3</span></sup>Field Research Center, Rockefeller University</center>
  <center style="font-size:18px;font-style:normal;color:black;"><sup><span style="font-size:12px;color:black;">4</span></sup>Department of Biological Sciences, University of Cincinnati</center>
  <br />
  <center style="font-size:18px;"><sup style="font-size:12px;">*</sup>gsvidaurre@gmail.com</center>
  &nbsp;
date: <center style="font-size:22px;font-style:normal";>`r format(Sys.time(), '%d %B, %Y')`</center>
  <br />
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float:
      collapsed: false
---

<style type="text/css">

a:hover {
  color: #23527c !important;
}

h1.title {
  font-size: 32px;
  color: black;
  font-weight: normal;
}

h1 {
   color: black;
   font-size: 26px;
   font-weight: normal;
}

h2 {
   color: black;
   font-size: 24px;
   font-weight: bold;
}

h3 {
   color: black;
   font-size: 20px;
   font-weight: normal;
}

h4 {
   color: black;
   font-size: 20px;
   font-weight: normal;
}

body{ /* Normal */
      font-size: 18px;
  }
  
code.r{ /* Code block */
    font-size: 18px;
}
</style>

```{r global options, include = FALSE}

knitr::opts_knit$set(root.dir = "/home/gsvidaurre/Desktop/GitHub_repos/identity-information-post-introduction", echo = TRUE, include = TRUE, eval = TRUE)

knitr::opts_chunk$set(root.dir = "/home/gsvidaurre/Desktop/GitHub_repos/identity-information-post-introduction", echo = TRUE, include = TRUE, eval = TRUE)

```

Call similarity across ranges and social scales was measured by spectrographic cross-correlation (SPCC) on spectrograms and Mel-frequency cepstral coefficients. We then used SPCC similarity within and among repeatedly sampled individuals per range (the individual scale dataset) to identify a similarity threshold that could be applied to identify calls most likely to represent repeated sampling of unmarked individuals at the site scale. This threshold was used to filter the site-scale calls, and we validated the use of clustering via Gaussian mixture models to identify potential repeated sampling of individuals. Next, we chose calls that would be visually classified in a Shiny app. Calls were selected for  training module and prediction modules. Finally, we validated the use of SPCC versus random forests similarity (using native range individuals and a random forests similarity matrix from previous work<a href='#References'><sup>[1]</sup></a>) to identify potential repeated individuals via Gaussian mixture models. See the methods and appendix of the associated publication for more information about these analyses.

This code was originally run with R version 3.4.4 and package versions reported for previous work<a href='#References'><sup>[1]</sup></a>. The RMarkdown output was knitted with a later version of R (see session info at the end of the script).

Check out Github repositories from previous work for related analyses and code:

- [gsvidaurre/strong-individual-signatures](https://github.com/gsvidaurre/strong-individual-signatures)<a href='#References'><sup>[1]</sup></a>

- [gsvidaurre/simpler-signatures-post-invasion](https://github.com/gsvidaurre/simpler-signatures-post-invasion)<a href='#References'><sup>[2]</sup></a>

Please cite both the associated papers and code (see DOIs on GitHub) if the code or analyses in these repositories are useful for your own research.
```{r load libraries, message = FALSE, warning = FALSE}

rm(list = ls())

X <- c("warbleR", "pbapply", "Rraven", "tidyverse", "ggplot2", "data.table", "lubridate", "mclust", "viridis", "scales", "knitr")
invisible(lapply(X, library, character.only = TRUE))

# Suppress summarise warnings from dplyr
options(dplyr.summarise.inform = FALSE)

path <- "/media/gsvidaurre/MYIOPSITTA/R/VocalLearning_PostDisruption/Data"
gpath <- "/media/gsvidaurre/MYIOPSITTA/R/VocalLearning_PostDisruption/Graphics"

seed <- 401

cores <- parallel::detectCores() - 2
# cores

```

Read in the extended selection table (EST) that contains metadata and wave objects for pre-processed native and introduced range calls across the individual and site scales.
```{r echo = TRUE, eval = TRUE}

nat_int_est <- readRDS(file.path(path, "monk_parakeet_contactCalls_rangeComparison_extSelTable.RDS"))
glimpse(nat_int_est)

```

# Measuring SPCC similarity

Run SPCC for the native and introduced range calls at both social scales. Perform SPCC on spectrograms and Mel-frequency cepstral coefficients (MFCC).
```{r chunk2, eval = FALSE}

xc_mat <- warbleR::xcorr(nat_int_est, wl = 378, ovlp = 90, wn = "hanning", cor.method = "pearson", parallel = cores, na.rm = FALSE, bp = c(0.5, 9), cor.mat = TRUE, path = path, type = "spectrogram")
str(xc_mat)

saveRDS(xc_mat, file.path(path, "xc_mat_NAT_INT.RDS"))

xc_mat_mfcc <- warbleR::xcorr(nat_int_est, wl = 378, ovlp = 90, wn = "hanning", cor.method = "pearson", parallel = cores, na.rm = FALSE, bp = c(0.5, 9), cor.mat = TRUE, path = path, type = "mfcc")
str(xc_mat_mfcc)

saveRDS(xc_mat_mfcc, file.path(path, "xc_mat_NAT_INT_mfcc.RDS"))

```

# Choosing a threshold to filter calls for visual classification

This step was carried out in preparation for multi-observer visual classification. During initial testing of the Shiny app used for visual classification, Valeria and I tried classifying all calls per site for a handful of site-years, and found this very difficult. One of the challenges in setting up a Shiny app for visual classification was to identify the calls that were most likely to represent potential repeated sampling of individuals per site-year, so as to make better use of everyone's time. 

Although it might seem circular, using a similarity threshold to filter calls prior to visual classification could help reduce the number of calls that co-authors would have to visually assess. I proceeded by using all known repeatedly sampled individuals (the individual scale dataset).

I parsed SPCC similarity within and among known repeatedly sampled individuals to assess overlap in the distributions of these two groups of similarity values. Here, for the comparisons among individuals, I compared individuals within site-years only, which will also be the case in the Shiny app given to co-authors to identify potential repeated sampling of individuals. Some individuals were the single bird sampled at a given site-year, so these received NAs for the among individual comparisons.
```{r chunk3}

xc_mat <- readRDS(file.path(path, "xc_mat_NAT_INV.RDS"))
xc_mat_mfcc <- readRDS(file.path(path, "xc_mat_NAT_INT_mfcc.RDS"))

# Change dimnames for grepping
dimnames(xc_mat) <- list(gsub(".WAV-1", ".WAV", dimnames(xc_mat)[[1]]), gsub(".WAV-1", ".WAV", dimnames(xc_mat)[[2]]))
dimnames(xc_mat_mfcc) <- list(gsub(".WAV-1", ".WAV", dimnames(xc_mat_mfcc)[[1]]), gsub(".WAV-1", ".WAV", dimnames(xc_mat_mfcc)[[2]]))

# str(dimnames(xc_mat))

# Loop over methods and ranges
method <- c("spectro", "MFCC")
mat_list <- list(xc_mat, xc_mat_mfcc)
pop <- c("Native", "Introduced")

# List all knwon repeatedly sampled individuals per range
indivs <- list(
  nat_int_est %>%
    filter(social_scale == "Individual") %>%
    filter(range == "Native") %>%
    mutate(
      Bird_ID = as.character(Bird_ID)
    ) %>%
    pull(Bird_ID) %>%
    unique(), 
  nat_int_est %>%
    filter(social_scale == "Individual") %>%
    filter(range == "Introduced") %>%
    mutate(
      Bird_ID = as.character(Bird_ID)
    ) %>%
    pull(Bird_ID) %>%
    unique())

indivs

# x <- 1 # SPCC method
# i <- 1 # range
# z <- 3 # individual
SPCC_vals_df <- rbindlist(invisible(pblapply(1:length(method), function(x){
  
  res2 <- rbindlist(lapply(1:length(pop), function(i){
    
    # Iterate over individuals for the given range
    res <- rbindlist(lapply(1:length(indivs[[i]]), function(z){
      
      # Get sound files for the right range and individuals
      tmp <- nat_int_est[grepl(pop[i], nat_int_est$range) & grepl(paste(paste("^", indivs[[i]][z], "$", sep = ""), collapse = "|"), nat_int_est$Bird_ID), ]
      # glimpse(tmp)
    
      calls <- tmp$sound.files
      
      # Subset the similarity matrix by calls for the given individual, to get within individual similarity scores
      tmp_mat <- mat_list[[x]][grepl(paste(paste("^", calls, "$", sep = ""), collapse = "|"), dimnames(mat_list[[x]])[[1]]), grepl(paste(paste("^", calls, "$", sep = ""), collapse = "|"), dimnames(mat_list[[x]])[[2]])]
      # str(tmp_mat)
    
      w <- tmp_mat[lower.tri(tmp_mat, diag = FALSE)]
  
      # Subset the similarity matrix by the given calls to get similarity values among the given individual and all others at the same site-year
      site_yr <- unique(nat_int_est$site_year[grepl(pop[i], nat_int_est$range) & grepl(paste("^", indivs[[i]][z], "$", sep = ""), nat_int_est$Bird_ID)])
      # site_yr
      
      # Get sound files for the given individual and all others at the same site-year
      calls2 <- nat_int_est$sound.files[nat_int_est$social_scale == "Individual" & grepl(pop[i], nat_int_est$range) & grepl(paste("^", site_yr, "$", sep = ""), nat_int_est$site_year) & !grepl(paste(paste("^", calls, "$", sep = ""), collapse = "|"), nat_int_est$sound.files)]
      
      # Looks good
      # calls
      # calls2
      
      # Account for individuals that had no others sampled at the same site
      if(length(calls2) > 0){
        
        a <- as.vector(mat_list[[x]][grep(paste(paste("^", calls, "$", sep = ""), collapse = "|"), dimnames(mat_list[[x]])[[1]]), grep(paste(paste("^", calls2, "$", sep = ""), collapse = "|"), dimnames(mat_list[[x]])[[2]])])
  
      
      # If no other birds sampled at the same site_year, return NA for among individual similarity
      } else if(length(calls2) == 0){
        
        a <- NA
        
      }
  
     return(data.frame(method = method[x], range = pop[i], site_year = site_yr, indiv = indivs[[i]][z], SPCC_vals = c(w, a), type = c(rep("Same", length(w)), rep("Different", length(a)))))
      
    }))
    
    
    # str(res)
    
    return(res)
    
  }))
  
  # str(res2)
  return(res2)
  
})))

# Change factor levels for plotting
SPCC_vals_df <- SPCC_vals_df %>%
  mutate(
    range = factor(range, levels = c("Native", "Introduced")),
    method = factor(method, levels = c("spectro", "MFCC")),
    type = factor(type, levels = c("Same", "Different"))
  )
  
glimpse(SPCC_vals_df)

```

I checked out the distribution of SPCC values within and among known repeatedly sampled individuals. I did this by range, type and method. 
```{r chunk4, message = FALSE, warning = FALSE}

tmp_spec <- SPCC_vals_df %>%
  filter(method == "spectro") %>%
  droplevels()

spec_means <- tapply(tmp_spec$SPCC_vals, list(tmp_spec$type, tmp_spec$range), mean, na.rm = TRUE)
spec_means

tmp_mfcc <- SPCC_vals_df %>%
  filter(method == "MFCC") %>%
  droplevels()

mfcc_means <- tapply(tmp_mfcc$SPCC_vals, list(tmp_mfcc$type, tmp_mfcc$range), mean, na.rm = TRUE)
mfcc_means

# Make a dummy df for plotting mean lines below
dum_df <- data.frame(type = rep(levels(SPCC_vals_df$type), 2), range = rep(levels(SPCC_vals_df$range), each = 2), method = rep(levels(SPCC_vals_df$method), each = 4), mean_val = c(
  spec_means[grepl("Same", rownames(spec_means)), grepl("Native", colnames(spec_means))],
  spec_means[grep("Different", rownames(spec_means)), grepl("Native", colnames(spec_means))],
  spec_means[grepl("Same", rownames(spec_means)), grepl("Introduced", colnames(spec_means))],
  spec_means[grep("Different", rownames(spec_means)), grepl("Introduced", colnames(spec_means))],
  mfcc_means[grepl("Same", rownames(mfcc_means)), grepl("Native", colnames(mfcc_means))],
  mfcc_means[grep("Different", rownames(mfcc_means)), grepl("Native", colnames(mfcc_means))],
  mfcc_means[grepl("Same", rownames(mfcc_means)), grepl("Introduced", colnames(mfcc_means))],
  mfcc_means[grep("Different", rownames(mfcc_means)), grepl("Introduced", colnames(mfcc_means))]
  ))
dum_df

cols <- alpha(c("gray35", "forestgreen"), 0.85)

# x11()
ggplot(data = SPCC_vals_df, aes(x = SPCC_vals)) +
  geom_histogram(aes(fill = type)) +
  scale_fill_manual(values = cols) +
  facet_grid(range ~ type + method) +
  geom_vline(data = dum_df, aes(xintercept = mean_val), linetype = "dashed") + 
  geom_text(data = dum_df, aes(x = mean_val + 0.25, y = 600, label = round(mean_val, 3))) +
  theme_bw() + 
  theme(
    legend.position = "top"
  )

```

By type and method across ranges combined (native and introduced).
```{r chunk5, message = FALSE, warning = FALSE}

means <- tapply(SPCC_vals_df$SPCC_vals, list(SPCC_vals_df$type, SPCC_vals_df$method), mean, na.rm = TRUE)
means

# Make a dummy df for plotting mean lines below
dum_df <- data.frame(type = rep(levels(SPCC_vals_df$type), 2), method = rep(levels(SPCC_vals_df$method), each = 2), mean_val = c(
  means[grepl("Same", rownames(means)), grepl("spectro", colnames(means))],
  means[grep("Different", rownames(means)), grepl("spectro", colnames(means))],
  means[grepl("Same", rownames(means)), grepl("MFCC", colnames(means))],
  means[grep("Different", rownames(means)), grepl("MFCC", colnames(means))]
))
dum_df

# x11()
ggplot(SPCC_vals_df, aes(x = SPCC_vals)) +
  geom_histogram(aes(fill = type)) +
  scale_fill_manual(values = cols) +
  geom_vline(data = dum_df, aes(xintercept = mean_val), linetype = "dashed") +
  facet_wrap(method ~ type) + 
  geom_text(data = dum_df, aes(x = mean_val + 0.25, y = 600, label = round(mean_val, 3))) +
  theme_bw() + 
  theme(
    legend.position = "top"
  )

```

Types combined in overlapping histograms by method, ranges combined.
```{r chunk6, message = FALSE, warning = FALSE}

cols <- alpha(c("gray35", "forestgreen"), 0.65)

SPCC_vals_df_tmp <- SPCC_vals_df %>%
  mutate(
    method = as.character(method),
    method = paste("SPCC", method, sep = "-")
  )

# x11()
SPCC_vals_df_tmp %>%
  ggplot(aes(x = SPCC_vals)) +
  geom_histogram(data = SPCC_vals_df_tmp %>%
                   filter(type == "Same") %>% droplevels(),
                    aes(fill = type), bins = 100) +
  geom_histogram(data = SPCC_vals_df_tmp %>%
                   filter(type == "Different") %>% droplevels(),
                    aes(fill = type), bins = 100) +
  facet_wrap(~ method) +
  scale_fill_manual(values = cols) +
  guides(fill = guide_legend(title = "Individual")) +
  theme_bw() + 
  theme(
    legend.position = "top"
  )

```

From these graphics it was clear that SPCC on spectrograms picked up a cleaner split within versus among individuals than SPCC on cepstral coefficients. In other words, there was less overlap in the distributions of the within versus among individual similarity values using SPCC on spectrograms.

# SPCC similarity threshold

Next, I identified the SPCC similarity threshold that we used to pull out calls for visual classification in the Shiny app. I found the maximum value of the bin of SPCC values for which there was less overlap than expected by chance (50%) between the two distributions (e.g. similarity values that represented the calls of the same versus different known repeatedly sampled individuals compared to each other). I iterated over multiple bin numbers to identify an appropriate bin, as the choice of bin number affected the amount of overlap between distributions. Then I selected the bin number that yielded the highest of the minimum SPCC values representing < 50% overlap in the within versus among individual distributions. The minimum SPCC value for the given bin was selected as the SPCC similarity threshold that we used to select calls for visual classification.
```{r chunk7, warning = FALSE, message = FALSE}

withn <- SPCC_vals_df %>%
  filter(method == "spectro") %>% 
  filter(type == "Same") %>% 
  droplevels() %>%
  filter(!is.na(SPCC_vals)) %>%
  pull(SPCC_vals)
head(withn)

amng <- SPCC_vals_df %>%
  filter(method == "spectro") %>% 
  filter(type == "Different") %>% 
  droplevels() %>%
  filter(!is.na(SPCC_vals)) %>%
  pull(SPCC_vals)
head(amng)

# Set the mean value of the Different category
spectro_df <- SPCC_vals_df %>%
  filter(method == "spectro") %>%
  droplevels()

means <- tapply(spectro_df$SPCC_vals, spectro_df$type, mean, na.rm = TRUE)
Dmean <- means[grep("Diff", names(means))]
Dmean

bins <- seq(25, 500, 25)
length(bins)
bins

# The within and among values should be combined into the same object, and then split into bins, for the fairest split into bins
tmp_dfO <- data.frame(type = c(rep("Same", length(withn)), rep("Different", length(amng))), vals = c(withn, amng))
glimpse(tmp_dfO)

# Order the data frame by SPCC values
tmp_dfO <- tmp_dfO[order(tmp_dfO$vals, decreasing = FALSE), ]
glimpse(tmp_dfO)

# i <- 2
bin_df <- rbindlist(invisible(pblapply(1:length(bins), function(i){
  
  # Filter the SPCC values by those greater than or equal to the mean of the Different category
  tmp_df <- tmp_dfO[tmp_dfO$vals >= Dmean, ]
  
  # Initialize the breaks for splitting SPCC values into the given number of bins
  brks <- seq(min(tmp_df$vals), max(tmp_df$vals), length.out = bins[i])
  # length(brks)

  # Split the SPCC vector into bins
  
  # Values in x are coded according to the interval in which they fall
  # Not all intervals will have values
  brk_tmp <- cut(tmp_df$vals, breaks = brks, include.lowest = TRUE, labels = FALSE)
  # glimpse(brk_tmp)

  # Add this vector of bins back to the data frame
  tmp_df2 <- tmp_df %>%
    mutate(
      bins = factor(brk_tmp)
    )
  # glimpse(tmp_df2)
  # table(tmp_df2$bins, tmp_df2$type)
  
  # Find the number of instances of each type (Same, Different) in each bin
  sum_df <- data.frame(tapply(tmp_df2$vals, list(tmp_df2$bins, tmp_df2$type), function(X){
    length(X)
  })) %>%
    mutate(
      Different = ifelse(is.na(Different), 0, Different),
      Same = ifelse(is.na(Same), 0, Same)
    ) %>%
    rowid_to_column() %>%
    rename(
      bin_num = rowid
    )
  # glimpse(sum_df)
  
  # Filter the data frame by rows in which Same has more values present than different per bin
  sum_df <- sum_df %>%
    filter(Same - Different > 0)
  sum_df
  
  # Percentages will be negative when Different has more values present than Same
  # x <- 1
  percnts <- unlist(lapply(1:nrow(sum_df), function(x){
    
    percnt <- ((sum_df$Different[x])/(sum_df$Same[x] + sum_df$Different[x]))*100
    # percnt

    return(percnt)
  
  }))
  percnts
  
  # percnts[which(percnts > 50)]
  min_bin <- min(sum_df$bin_num[which(abs(percnts) < 50)])
  min_bin
  
  # tmp_df2[tmp_df2$bins == as.character(min_bin), ]
  
  # mean(tmp_df2$vals[tmp_df2$bins == as.character(min_bin)])
  # min(tmp_df2$vals[tmp_df2$bins == as.character(min_bin)])
  
  return(data.frame(bins_used = bins[i], min_bin = min_bin, min_SPCC_val = min(tmp_df2$vals[tmp_df2$bins == as.character(min_bin)]), mean_SPCC_val = mean(tmp_df2$vals[tmp_df2$bins == as.character(min_bin)]), max_SPCC_val = max(tmp_df2$vals[tmp_df2$bins == as.character(min_bin)])))
  
  
})))

glimpse(bin_df)
# View(bin_df)

range(bin_df$min_SPCC_val)
max(bin_df$min_SPCC_val)

bin_val <- bin_df$bins_used[which(bin_df$min_SPCC_val == max(bin_df$min_SPCC_val))]
bin_val

# Taking the minimum SPCC value for the given bin at which Different values represent less than 50% of the sum of the Same and Different values
# Using bin_val/2 to set the number of bins of the histogram because in the loop above, the Same and Different values were binned all together, while here they are split in two
cols <- alpha(c("gray35", "forestgreen"), 0.65)

ggplot(spectro_df, aes(x = SPCC_vals)) +
  geom_histogram(data = spectro_df %>%
                   filter(type == "Same") %>% droplevels(),
                    aes(fill = type), bins = 100) +
  geom_histogram(data = spectro_df %>%
                   filter(type == "Different") %>% droplevels(),
                    aes(fill = type), bins = 100) +
  geom_vline(xintercept = bin_df$min_SPCC_val[bin_df$bins_used == bin_val], linetype = "dashed") +
  annotate("text", label = paste("SPCC threshold =", round(bin_df$min_SPCC_val[bin_df$bins_used == bin_val], 4)), x = 0.65, y = 200) +
  scale_fill_manual(values = cols) +
  guides(fill = guide_legend(title = "Individual")) +
  xlab("Similarity values") +
  ylab("Count") +
  theme_bw() + 
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 9),
    legend.title = element_text(size = 10),
    legend.text = element_text(size = 10),
    legend.position = "top",
    legend.key.size = unit(1, "lines"),
    panel.grid.major = element_line(size = 0.15),
    panel.grid.minor = element_line(size = 0.15),
    axis.ticks = element_line(size = 0.15),
    legend.margin = margin(1, 1, 1, 1),
    legend.box.margin = margin(-8, -8, -8, -8)
  )

```

Save the SPCC threshold for later use.
```{r chunk8, eval = FALSE}

thresh <- bin_df$min_SPCC_val[bin_df$bins_used == bin_val]
thresh # 0.4383545

saveRDS(thresh, file.path(path, "SPCC_thresh_indiv_scale.RDS"))

```

In sum, the threshold (shown as a vertical dotted line) was identified by splitting the SPCC values for the individual scale dataset into values within individuals (“Same”) and among individuals (“Different”), binning the distributions, and identifying the bin with SPCC values that exhibited less than 50% overlap between the SPCC distributions within and among individuals (e.g. less overlap within versus among individuals than expected by chance).

Calls that had any pairwise comparisons with SPCC similarity values above or equal to this threshold were retained for multi-observer visual inspection. While calls produced by the same individual did not always represent pairwise comparisons with SPCC values higher than this threshold (e.g. the lower half of the "same individual" distribution below the dotted line), using this threshold allowed us to reduce the number of calls that observers had to inspect down to the calls most likely to represent repeated individual sampling per site.

# Setting up training module for visual classification

For the Shiny app training module, I created training datasets that reflected the task that co-authors had to perform in the "prediction" module of the app. For site-years with known repeatedly sampled individuals (the individual scale dataset), I obtained the individual and site scale calls, and removed those below the SPCC threshold. Then I mixed randomly selected calls for each known repeatedly sampled bird at the given site with randomly selected site scale calls from that same site. Training accuracy per observer was evaluated by how many of the known repeatedly individual calls were classified together. Some of these sites with known repeatedly sampled birds may have also had calls that represented inadvertent repeated sampling of other individuals.

Gaussian mixture models were used to perform clustering on the calls selected for the training module, resulting in clusters that I treated as potential repeatedly sampled individuals. These clusters were the classes that I presented to observers in the app (see images used for visual checking below). Each site in the training module was presented on a single page, and calls were presented in groups (classes) by their assigned cluster.
```{r chunk9}

nat_int_est <- readRDS(file.path(path, "monk_parakeet_contactCalls_rangeComparison_extSelTable.RDS"))
# glimpse(nat_int_est)

xc_mat <- readRDS(file.path(path, "xc_mat_NAT_INT.RDS"))
# str(xc_mat)

# Change dimnames for grepping
dimnames(xc_mat) <- list(gsub(".WAV-1", ".WAV", dimnames(xc_mat)[[1]]), gsub(".WAV-1", ".WAV", dimnames(xc_mat)[[2]]))

# For Shiny app training: 3 known repeatedly sampled individuals (krsi) from 1145 with the most calls, 1 krsi from ROBE_2011 (INV) and 2 krsi from SOCC_2019 (INV) (3 training pages, one per site)
# Randomly sample 4 calls from each krsi, and randomly sample 15 calls from the given site_year, or take the total calls per site if less than 15
# From the pooled calls by site_year, filter out pairwise similarity values less than the SPCC threshold determined above, then retain the remaining calls
# Perform model-based clustering on calls, assess accuracy and whether or not this can be given straight to co-authors
nat_int_est %>%
  filter(social_scale == "Individual") %>%
  group_by(range, Bird_ID, site_year) %>%
  count()

# site_year BART_2011 was dropped after pre-processing
site_year <- c("1145_2017", "ROBE_2011", "ELEM_2019")
indivs <- list(c("NAT-UM1", "NAT-UM2", "NAT-UM4"), c("INV-UM5"), c("INV-UM7", "INV-UM9"))

thresh <- readRDS(file.path(path, "SPCC_thresh_indiv_scale.RDS"))

# x <- 3
# z <- 2
mBIC_res_list <- invisible(pblapply(1:length(site_year), function(x){
  
  # Get calls for the known repeatedly sampled individuals that will be used at this site
  icalls <- nat_int_est %>%
  filter(social_scale == "Individual") %>%
  filter(Bird_ID %in% indivs[[x]]) %>%
  mutate(
    sound.files = as.character(sound.files) 
  ) %>%
  pull(sound.files)
  icalls
  
  # If there are more than 4 calls per bird, randomly sample 4 calls per bird
  icalls <- unlist(lapply(1:length(indivs[[x]]), function(z){
    
    ic <- nat_int_est %>%
      filter(social_scale == "Individual") %>%
      filter(Bird_ID %in% indivs[[x]][z]) %>%
      mutate(
        sound.files = as.character(sound.files) 
      ) %>%
      pull(sound.files)
    
    if(length(ic) > 4){
      set.seed(seed)
      ic <- sample(ic, 4, replace = FALSE)
    }
    
    return(ic)
    
  }))
  
  # icalls
  
  # Get site scale calls that will be used at this site
  scalls <- nat_int_est %>%
  filter(social_scale == "Site")
  # glimpse(scalls)
  
  # Remove calls that have the suffix "_site_scale", since these represent 1 call per known repeatedly sampled individuals included at the site scale
  scalls <- scalls$sound.files[grepl(paste("^", site_year[x], "$", sep = ""), scalls$site_year)]
  
  if(any(grepl("_site_scale.WAV$", scalls))){
    scalls <- scalls[-grep("_site_scale.WAV$", scalls)]
  }

  # If there are more than 15 site scale calls, randomly sample 15 calls
  if(length(scalls) > 15){
    set.seed(seed)
    scalls <- sample(scalls, 15, replace = FALSE)
  }
  # scalls
  
  # Subset the SPCC spectro matrix by these individual AND site scale calls
  xc_mat_tmp <- xc_mat[grepl(paste(paste("^", c(icalls, scalls), "$", sep = ""), collapse = "|"), dimnames(xc_mat)[[1]]), grepl(paste(paste("^", c(icalls, scalls), "$", sep = ""), collapse = "|"), dimnames(xc_mat)[[2]])]
  # str(xc_mat_tmp)

  # Checking
  # dim(xc_mat_tmp) == length(c(icalls, scalls))
  
  # Make a data frame of pairwise comparisons
  # i <- 1
  # j <- 2
  pairvals <- rbindlist(lapply(1:nrow(xc_mat_tmp), function(i){
    df <- lapply(1:nrow(xc_mat_tmp), function(j){
      # Remove calls compared to themselves on the diagonal
      if(dimnames(xc_mat_tmp)[[1]][i] != dimnames(xc_mat_tmp)[[2]][j]){
        return(data.frame(SPCC_vals = xc_mat_tmp[i, j], call = dimnames(xc_mat_tmp)[[1]][i], compared2 = dimnames(xc_mat_tmp)[[2]][j]))
      }
    })
    return(rbindlist(df))
  }))
  # glimpse(pairvals)
  
  # Checking, looks good
  # nrow(pairvals) == (length(xc_mat_tmp) - length(c(icalls, scalls)))
  
  # Subset pairwise comparisons at the site scale to retain only those BELOW the SPCC threshold
  # range(pairvals$SPCC_vals[pairvals$SPCC_vals >= thresh])
  
  pairvals2 <- pairvals[pairvals$SPCC_vals >= thresh, ]
  # nrow(pairvals2)
  # View(pairvals2)

  # Which calls were dropped, if any?
  # wh <- unique(c(which(!dimnames(xc_mat_tmp)[[1]] %in% pairvals2$call), which(!dimnames(xc_mat_tmp)[[1]] %in% pairvals2$compared2)))

  # The calls that will be dropped after implementing the SPCC threshold  
  # For ELEM 2019, all calls for UM9 are dropped
  # dimnames(xc_mat_tmp)[[1]][wh]
  
  # Which calls remain?
  keep <- unique(c(as.character(pairvals2$call), as.character(pairvals2$compared2)))
  # keep

  # Subset the SPCC matrix to remove calls with pairwise comparison values lower than the SPCC threshold
  xc_mat_tmpf <- xc_mat_tmp[grepl(paste(paste("^", keep, "$", sep = ""), collapse = "|"), dimnames(xc_mat_tmp)[[1]]), grepl(paste(paste("^", keep, "$", sep = ""), collapse = "|"), dimnames(xc_mat_tmp)[[2]])]
  # str(xc_mat_tmpf)  # Looks good

  # Perform model-based clustering on the filtered matrix
  ids <- nat_int_est$Bird_ID[grepl(paste(paste("^", keep, "$", sep = ""), collapse = "|"), nat_int_est$sound.files)]

  # Give site scale calls unique IDs if they don't have one
  ids[is.na(ids)] <- paste("Site-Call", seq(1, length(ids[is.na(ids)])), sep = "")
  # ids
  
  # Don't give the algorithm a set number of clusters, let it find clusters in an unrestricted fashion
  set.seed(seed)
  mBIC <- mclust::Mclust(data = stats::as.dist(1 - xc_mat_tmpf, upper = TRUE, diag = TRUE))
  
  ss <- nat_int_est$social_scale[grepl(paste(paste("^", keep, "$", sep = ""), collapse = "|"), nat_int_est$sound.files)]

  mBIC_res <- data.frame(calls = keep, indiv = ids, cluster = as.vector(mBIC$classification), social_scale = ss)
  
  # Clustering results will be used to group calls for Shiny app (training and prediction modules)
  return(mBIC_res)
  
}))

names(mBIC_res_list) <- site_year
str(mBIC_res_list)

```

# Visual validation of training module approach

I made catalogs of calls that would be used for Shiny app training. These catalogs facilitated visual assessment of the structural similarity of calls assigned to the same and different clusters. I designed the Shiny app so that calls in each cluster would be presented together in the same class for visual inspection.
```{r chunk10, eval = FALSE}

# For catalogs to save in the right folder
setwd(path)

# x <- 1
invisible(pblapply(1:length(mBIC_res_list), function(x){
  
  tmp_est <- nat_int_est[grep(paste(paste("^", mBIC_res_list[[x]]$calls, "$", sep = ""), collapse = "|"), nat_int_est$sound.files), ]
  # glimpse(tmp_est)
  
  # Add the clustering data to the temporary EST
  tmp_est$cluster <- factor(unlist(sapply(1:nrow(tmp_est), function(i){
    mBIC_res_list[[x]]$cluster[grep(paste(paste("^", mBIC_res_list[[x]]$calls[i], "$", sep = ""), collapse = "|"), mBIC_res_list[[x]]$calls)]
  }, simplify = FALSE)))
  # glimpse(tmp_est)
  
  # Add an updated bird ID column, catalog() cannot handle the NAs
  # unique(tmp_est$Bird_ID)
  
  tmp_est$catalog_Bird_ID <- factor(unlist(sapply(1:nrow(tmp_est), function(i){
    mBIC_res_list[[x]]$indiv[grep(paste(paste("^", mBIC_res_list[[x]]$calls[i], "$", sep = ""), collapse = "|"), mBIC_res_list[[x]]$calls)]
  }, simplify = FALSE)))
  
  # Order the EST by cluster
  tmp_est <- tmp_est[order(tmp_est$cluster, decreasing = FALSE), ]

  catalog(X = tmp_est, flim = c(0.5, 9), nrow = 4, ncol = 4, ovlp = 90, wl = 378, orientation = "h", labels = c("catalog_Bird_ID", "social_scale", "cluster"), title = unique(tmp_est$site_year), mar = 0.01, cex = 0.85, img.suffix = paste("Shiny_app_training", names(mBIC_res_list)[[x]], sep = "_"), parallel = cores, path = path, tags = c("cluster", "catalog_Bird_ID"), tag.pal = list(magma, viridis), hatching = 2, res = 200, leg.wd = 10, lab.mar = 1.5)

  catalog2pdf(keep.img = FALSE, overwrite = TRUE, by.img.suffix = TRUE, path = path)
  
}))

```

![An example catalog page from the clustering performed for training calls:](/home/gsvidaurre/Desktop/GitHub_repos/identity-information-post-introduction/images/Shiny_app_training_1145_p1_scrnsht.png)

The catalogs for training looked pretty good. I saved these calls per site for the Shiny app training module. The header above each panel in the image of one catalog page above indicates 1) the social scale, 2) the cluster to which the call was assigned (e.g. the potential repeated individual identified via the clustering approach), 3) the individual ID. Colors correspond to clusters (potential repeated individuals) and hatching indicates individual IDs. Calls grouped into clusters were presented grouped together in the Shiny app itself.

# Writing out calls for training module 

```{r chunk11, eval = FALSE}

# Collapse the list from model-based clustering into a data frame
mBIC_res_df <- rbindlist(mBIC_res_list) %>%
  mutate(
    indiv = as.character(indiv)
  )
glimpse(mBIC_res_df)

# Get all the calls classified by model-based clustering above per site-year with pairwise similarity values above the SPCC threshold
# x <- 1
shiny_train_calls <- as.character(mBIC_res_df$calls)
head(shiny_train_calls)

# 44 calls will be used in training
length(shiny_train_calls)

# Subset the EST by these calls
inds <- grep(paste(paste("^", shiny_train_calls, "$", sep = ""), collapse = "|"), nat_int_est$sound.files)
# length(inds) == length(shiny_train_calls)

shiny_training_module_est <- nat_int_est[inds, ]
glimpse(shiny_training_module_est)

# Check out the site_years, looks good
table(shiny_training_module_est$site_year)

# Add the clustering data and new individual IDs to the EST
clusters <- unlist(invisible(pblapply(1:nrow(shiny_training_module_est), function(i){
  return(mBIC_res_df$cluster[grep(paste(paste("^", shiny_training_module_est$sound.files[i], "$", sep = ""), collapse = "|"), mBIC_res_df$calls)])
})))
head(clusters)

indiv_call_ID <- unlist(invisible(pblapply(1:nrow(shiny_training_module_est), function(i){
  return(mBIC_res_df$indiv[grep(paste(paste("^", shiny_training_module_est$sound.files[i], "$", sep = ""), collapse = "|"), mBIC_res_df$calls)])
})))
head(indiv_call_ID)

shiny_training_module_est$indiv_call_ID <- indiv_call_ID
shiny_training_module_est$cluster <- factor(clusters)

glimpse(shiny_training_module_est)

table(shiny_training_module_est$Bird_ID)

# All co-authors will also have to evaluate calls for the same 3 sites during training and achieve high accuracy in order to move on to the prediction module 

# Save this EST for the Shiny training module
saveRDS(shiny_training_module_est, file.path(path, "shiny_potrepindiv_training_module_est.RDS"))

```

# Clustering calls for the prediction module

Gaussian mixture modelling was used to cluster calls per site-year in the full dataset between ranges after implementing the SPCC similarity threshold.
```{r chunk12, eval = TRUE}

nat_int_est <- readRDS(file.path(path, "monk_parakeet_contactCalls_rangeComparison_extSelTable.RDS"))
# glimpse(nat_int_est)

xc_mat <- readRDS(file.path(path, "xc_mat_NAT_INT.RDS"))
# str(xc_mat)

# Change dimnames for grepping
dimnames(xc_mat) <- list(gsub(".WAV-1", ".WAV", dimnames(xc_mat)[[1]]), gsub(".WAV-1", ".WAV", dimnames(xc_mat)[[2]]))

# Filter the full EST by site scale calls
site_calls <- nat_int_est %>%
    filter(social_scale == "Site")

# Initialize unique site_years across this dataset
site_year <- unique(site_calls$site_year)
site_year

# 63 sites in the full dataset across the native and introduced range
length(site_year)

# Initialize the SPCC threshold
thresh <- readRDS(file.path(path, "SPCC_thresh_indiv_scale.RDS"))
thresh

# x <- 1
mBIC_res_list <- invisible(pblapply(1:length(site_year), function(x){

  # Get calls for this site_year
  calls <- site_calls$sound.files[grep(paste("^", site_year[x], "$", sep = ""), site_calls$site_year)]
  
  # Subset the SPCC spectrogram matrix by these site scale calls
  xc_mat_tmp <- xc_mat[grepl(paste(paste("^", calls, "$", sep = ""), collapse = "|"), dimnames(xc_mat)[[1]]), grepl(paste(paste("^", calls, "$", sep = ""), collapse = "|"), dimnames(xc_mat)[[2]])]
  # str(xc_mat_tmp)

  # Checking
  # dim(xc_mat_tmp) == length(calls)
  
  # Make a data frame of pairwise comparisons
  pairvals <- rbindlist(lapply(1:nrow(xc_mat_tmp), function(i){
    df <- lapply(1:nrow(xc_mat_tmp), function(j){
      # Remove calls compared to themselves on the diagonal
      if(dimnames(xc_mat_tmp)[[1]][i] != dimnames(xc_mat_tmp)[[2]][j]){
        return(data.frame(SPCC_vals = xc_mat_tmp[i, j], call = dimnames(xc_mat_tmp)[[1]][i], compared2 = dimnames(xc_mat_tmp)[[2]][j]))
      }
    })
    return(rbindlist(df))
  }))
  # glimpse(pairvals)
  # nrow(pairvals) == (length(xc_mat_tmp) - length(calls))
  
  # Subset pairwise comparisons to retain only those above the SPCC threshold
  # range(pairvals$SPCC_vals[pairvals$SPCC_vals >= thresh])
  
  pairvals2 <- pairvals[pairvals$SPCC_vals >= thresh, ] %>%
    mutate(
      call = as.character(call),
      compared2 = as.character(compared2)
    )
  # nrow(pairvals2)

  # Which calls were dropped, if any?
  # wh <- unique(c(which(!dimnames(xc_mat_tmp)[[1]] %in% pairvals2$call), which(!dimnames(xc_mat_tmp)[[2]] %in% pairvals2$compared2)))

  # The calls that will be dropped after implementing the SPCC threshold  
  # dimnames(xc_mat_tmp)[[1]][wh]
  
  # Which calls remain?
  keep <- unique(c(pairvals2$call, pairvals2$compared2))
  # keep
  
  # Subset the SPCC matrix to remove calls with pairwise comparison values lower than the SPCC threshold
  xc_mat_tmpf <- xc_mat_tmp[grepl(paste(paste("^", keep, "$", sep = ""), collapse = "|"), dimnames(xc_mat_tmp)[[1]]), grepl(paste(paste("^", keep, "$", sep = ""), collapse = "|"), dimnames(xc_mat_tmp)[[2]])]
  # str(xc_mat_tmpf)  # Looks good

  if(nrow(xc_mat_tmpf) > 0){
    
    # Perform model-based clustering on the filtered matrix
    ids <- nat_int_est$Bird_ID[grepl(paste(paste("^", keep, "$", sep = ""), collapse = "|"), nat_int_est$sound.files)]

    # Give site scale calls unique IDs if they don't have one
    ids[is.na(ids)] <- paste(paste("PotRepIndiv-Call", seq(1, length(ids[is.na(ids)])), sep = ""), sep = "-")
    # ids
  
    # Don't give the algorithm a set number of clusters, let it find clusters in an unrestricted fashion
    set.seed(seed)
    mBIC <- mclust::Mclust(data = stats::as.dist(1 - xc_mat_tmpf, upper = TRUE, diag = TRUE))

    mBIC_res <- data.frame(calls = keep, indiv = ids, cluster = as.vector(mBIC$classification))
  
    return(mBIC_res)
    
  } else if(nrow(xc_mat_tmpf) == 0){
   
    return(NA) 
    
  }
  
}))

names(mBIC_res_list) <- site_year
str(mBIC_res_list[1:5])

# LAKE_2011 had no pairwise similarity values above or equal to the SPCC threshold
# which(is.na(mBIC_res_list))

# How many calls remain per each of the 62 sites with pairwise similarity values above the SPCC threshold?
mBIC_res_list2 <- mBIC_res_list[-which(is.na(mBIC_res_list))]
# str(mBIC_res_list2[1:5])
length(mBIC_res_list2)
# names(mBIC_res_list2)

numc <- sapply(1:length(mBIC_res_list2), function(i){
  length(mBIC_res_list2[[i]]$calls)
})
numc

# Eight sites have >30 calls remaining, ranging from 45 - 90 calls
length(numc[numc > 30])
range(numc[numc > 30])

```

62 sites were flagged for visual classification of possible repeated sampling of individuals across 6 co-authors. I aimed for the following distribution of visual classification tasks:

  - assign 2 sites to first author, which leaves 60 sites to assign across co-authors
  - divided the remaining 60 equally among co-authors
  - every observer gets 3 training + around 10 prediction sites
  - every observer is also assigned the same 4 sites to assess multi-observer reliability in the prediction module, ideally 2 sites with few calls and 2 with many calls
  - no more than 17 sites assigned to each observer

# Visual validation of clusters for prediction dataset

I made catalogs of calls identified for the Shiny app for a few sites to assess how calls were assigned to clusters (to be used as classes representing possible repeatedly sampled individuals in the prediction module).
```{r chunk13, eval = FALSE}

setwd(path)

site_yrs <- c("1145_2017", "SOCC_2019", "BALL_2004")

# x <- 1
invisible(pblapply(1:length(site_yrs), function(x){
  
  tmp_est <- nat_int_est[grep(paste(paste("^", mBIC_res_list2[[site_yrs[x]]]$calls, "$", sep = ""), collapse = "|"), nat_int_est$sound.files), ]
  # glimpse(tmp_est)
  
  # Add the clustering data to the temporary EST
  tmp_est$cluster <- factor(unlist(sapply(1:nrow(tmp_est), function(i){
    mBIC_res_list2[[site_yrs[x]]]$cluster[grep(paste(paste("^", mBIC_res_list2[[site_yrs[x]]]$calls[i], "$", sep = ""), collapse = "|"), mBIC_res_list2[[site_yrs[x]]]$calls)]
  }, simplify = FALSE)))
  # glimpse(tmp_est)
  
  # Add an updated bird ID column, catalog() cannot handle the NAs
  # unique(tmp_est$Bird_ID)
  
  tmp_est$pot_rep_Bird_ID <- factor(unlist(sapply(1:nrow(tmp_est), function(i){
    mBIC_res_list2[[site_yrs[x]]]$indiv[grep(paste(paste("^", mBIC_res_list2[[site_yrs[x]]]$calls[i], "$", sep = ""), collapse = "|"), mBIC_res_list2[[site_yrs[x]]]$calls)]
  }, simplify = FALSE)))
  
  # Order the EST by cluster, since I feel catalog makes things more confusing with the group.tag argument
  tmp_est <- tmp_est[order(tmp_est$cluster, decreasing = FALSE), ]
  
  # , "sound.files"
  catalog(X = tmp_est, flim = c(0.5, 9), nrow = 4, ncol = 4, ovlp = 90, wl = 378, orientation = "h", labels = c("pot_rep_Bird_ID", "social_scale", "cluster"), title = unique(tmp_est$site_year), mar = 0.01, cex = 0.85, img.suffix = paste("Shiny_app_prediction", site_yrs[x], sep = "_"), parallel = cores, path = path, tags = c("cluster", "pot_rep_Bird_ID"), tag.pal = list(magma, viridis), hatching = 2, res = 200, leg.wd = 10, lab.mar = 1.5, sub.legend = TRUE)

  catalog2pdf(keep.img = FALSE, overwrite = TRUE, by.img.suffix = TRUE, path = path)
  
}))

```

![An example catalog page from the clustering performed for prediction calls:](/home/gsvidaurre/Desktop/GitHub_repos/identity-information-post-introduction/images/Shiny_app_prediction_SOCC_2019p5_scrnsht.png)

The clustering approach sometimes grouped visibly similar calls together, but it didn't perform well for all calls. For instance, sometimes calls that looked similar enough to be the same individual were assigned to different clusters, and sometimes a cluster contained calls that were visibly distinct enough to be different individuals (see example image above). I set up the Shiny app to prompt observers to remove calls from clusters (classes in the app) that looked structurally different, and to create new classes if they felt there are more potential repeatedly sampled individuals than the classes generated by clustering. Again, calls in the catalog that were assigned to the same cluster (indicated with colors) were presented together as the same potential repeated individual in the Shiny app.

# Assigning calls to co-authors for prediction module 

How to split up this data for the app? This depended a lot on how to make the app available to co-authors. I set up the app to upload to Dropbox (I did not enough expertise to set up remote data storage), which required each co-author have a copy of the app on their local machine.

I generated an EST for the Shiny prediction module. This contained the new IDs per call, the classes identified through clustering, and co-authors' usernames per call to indicate which should be pulled out per observer.
```{r chunk14, eval = FALSE}

# Collapse the list from model-based clustering into a data frame
mBIC_res_df <- rbindlist(mBIC_res_list2) %>%
  mutate(
    indiv = as.character(indiv)
  )
glimpse(mBIC_res_df)

# Get all the calls classified by model-based clustering above per site-year with pairwise similarity values above the SPCC threshold
# x <- 1
shiny_test_calls <- as.character(mBIC_res_df$calls)
head(shiny_test_calls)

# 1113 calls will be used in the prediction module
length(shiny_test_calls)
# nrow(site_calls) - length(shiny_test_calls) # 254 site scale calls will bypass this step

# 81.42% of the site scale data will be evaluated for potential repeated sampling of individuals
length(shiny_test_calls)/nrow(nat_int_est %>%
                        filter(social_scale == "Site"))

# 18.58% of site scale calls will not be evaluated
(nrow(site_calls) - length(shiny_test_calls))/nrow(nat_int_est %>%
                        filter(social_scale == "Site"))

# Subset the EST by these calls
inds <- grep(paste(paste("^", shiny_test_calls, "$", sep = ""), collapse = "|"), nat_int_est$sound.files)
# length(inds) == length(shiny_test_calls)

shiny_prediction_module_est <- nat_int_est[inds, ]
glimpse(shiny_prediction_module_est)

# Add the clustering data and new indiv IDs to the EST
clusters <- unlist(invisible(pblapply(1:nrow(shiny_prediction_module_est), function(i){
  return(mBIC_res_df$cluster[grep(paste(paste("^", shiny_prediction_module_est$sound.files[i], "$", sep = ""), collapse = "|"), mBIC_res_df$calls)])
})))
head(clusters)

pot_rep_indiv <- unlist(invisible(pblapply(1:nrow(shiny_prediction_module_est), function(i){
  return(mBIC_res_df$indiv[grep(paste(paste("^", shiny_prediction_module_est$sound.files[i], "$", sep = ""), collapse = "|"), mBIC_res_df$calls)])
})))
head(pot_rep_indiv)

shiny_prediction_module_est$pot_rep_indiv_ID <- pot_rep_indiv
shiny_prediction_module_est$cluster <- factor(clusters)

glimpse(shiny_prediction_module_est)

table(shiny_prediction_module_est$Bird_ID)

```

I assigned calls to observers by randomly selecting 2 sites for the first author, then I randomly selected 10 sites for each co-author. Finally, I selected 4 sites that everyone would assess, for the purpose of multi-observer reliability analyses.
```{r chunk15, eval = FALSE}

site_years <- unique(shiny_prediction_module_est$site_year)
site_years

set.seed(seed)
first_auth <- sample(site_years, 2, replace = FALSE) 
first_auth

# Six co-authors, 10 sites each after removing 2 sites for 1st author
site_years2 <- site_years[-grep(paste(paste("^", first_auth, "$", sep = ""), collapse = "|"), site_years)]
site_years2

set.seed(seed)
rsamp <- split(site_years2, sample(site_years2, 6, replace = FALSE))      

# Get call numbers
lapply(1:length(rsamp), function(x){
  length(grep(paste(paste("^", rsamp[[x]], "$", sep = ""), collapse = "|"), shiny_prediction_module_est$site_year))
})

# ASM, EAH and TFW should get the site assignments with the least number of calls, while GSV (1st author), VPZ and DLH can parse more calls. Initialize co-authors to reflect this. See below: after adding the 4 sites that everyone will score, tfw and gsv should be switched to reflect greater number of calls assigned to gsv
co_authors <- c("dlh", "tfw", "asm", "gsv", "vpz", "eah")
names(rsamp) <- co_authors
rsamp

# Add the 2 randomly sampled 1st author sites to the 1st author assignment list
rsamp$gsv <- c(rsamp$gsv, first_auth)

# Add the co-author initials to the EST by site
co_author_initials <- unlist(invisible(pblapply(1:nrow(shiny_prediction_module_est), function(i){
  # Returns the index for the list of sites in which this site occurs
  list_ind <- grep(shiny_prediction_module_est$site_year[i], rsamp)
  return(names(rsamp[list_ind]))
})))
co_author_initials

shiny_prediction_module_est$co_author_initials <- co_author_initials

# Double-checking, looks good
all(unique(shiny_prediction_module_est$site_year[grep("gsv", shiny_prediction_module_est$co_author_initials)]) %in% rsamp[["gsv"]])

all(rsamp[["gsv"]] %in% unique(shiny_prediction_module_est$site_year[grep("gsv", shiny_prediction_module_est$co_author_initials)]))

# Check out numbers of calls assigned to each co-author
table(shiny_prediction_module_est$co_author_initials)

# These numbers will even out once I evenly assign the sites that will be evaluated across all co-authors 

# Which 4 sites (2 small, 2 large) will be assigned to all co-authors?
table(shiny_prediction_module_est$site_year, shiny_prediction_module_est$co_author_initials)

# Two small (INV, NAT): BALL_2004, CISN_2017 
# Two large (INV, NAT): SOCC_2019, SOCC_2004

# Add all co-author initials to the co-author column for these sites
shiny_prediction_module_est$co_author_initials[grep(paste(paste("^", c("BALL_2004", "CISN_2017", "SOCC_2019", "SOCC_2004"), "$", sep = ""), collapse = "|"), shiny_prediction_module_est$site_year)] <- paste(co_authors, collapse = "|")

# 217 calls across 4 sites will be evaluated by all co-authors
table(shiny_prediction_module_est$co_author_initials)

# How many calls will each co-author evaluate in the prediction module once these 4 sites are added? 
ca_nums <- sapply(1:length(co_authors), function(i){
  length(grep(co_authors[i], shiny_prediction_module_est$co_author_initials))
})

# Looks good, matches the amount of effort that co-authors should be able to provide
paste(co_authors, ca_nums, sep = ": ")

# All co-authors will also have to evaluate calls for the same 3 sites during training and achieve high accuracy in order to move on to the prediction module 

# Save this EST for the Shiny prediction module
saveRDS(shiny_prediction_module_est, file.path(path, "shiny_potrepindiv_prediction_module_est.RDS"))

```

# Validation of SPCC versus random forests for similarity threshold

What if random forests similarity provided better clustering performance? If so, using random forests similarity could provide co-authors with better groupings of calls from the start, and I should wait to send out the app until obtaining random forests similarity for all calls.

I validated this possibility by comparing clustering results on the same individuals/calls used in random forests model validation for the native range to SPCC clustering performance.
```{r chunk16, eval = TRUE}

rf_mat <- readRDS(file.path("/media/gsvidaurre/MYIOPSITTA/R/Uruguay2017_MonkParakeet_CallAnalysis/Data/Site_Recordings", "proxm_ms.RDS"))
str(rf_mat)

sup_rf_comb_pp <- readRDS(file.path("/media/gsvidaurre/MYIOPSITTA/R/Uruguay2017_MonkParakeet_CallAnalysis/Data/Site_Recordings", "sup_rf_comb_preprocessed.RDS"))
dim(sup_rf_comb_pp)

sup_rf_val <- sup_rf_comb_pp %>%
  filter(set == "validatn")
dim(sup_rf_val)
names(sup_rf_val)

nat_nms <- paste(gsub(".WAV-", "_", sup_rf_val$uniq_call_ID), ".WAV", sep = "")
nat_nms

dimnames(rf_mat) <- list(nat_nms, nat_nms)

# Call ID isn't necessary, since we took all calls for 1/2 of individuals for training, and the rest of the individuals for validation
nat_indivs <- c("RAW", "ZW8", "UM3", "UM5")

xc_mat <- readRDS(file.path(path, "xc_mat_NAT_INV.RDS"))
str(xc_mat)

# Change dimnames for grepping
dimnames(xc_mat) <- list(gsub(".WAV-1", ".WAV", dimnames(xc_mat)[[1]]), gsub(".WAV-1", ".WAV", dimnames(xc_mat)[[2]]))

# Subset the SPCC matrix by the individuals used in the native range random forests validation. Here searching for calls associated with these IDs
nat_calls <- nat_int_est %>%
  filter(social_scale == "Individual") %>%
  filter(Bird_ID %in% paste("NAT", nat_indivs, sep = "-")) %>%
  pull(sound.files)
nat_calls

xc_mat_sub <- xc_mat[grep(paste(paste("^", nat_calls, "$", sep = ""), collapse = "|"), dimnames(xc_mat)[[1]]), grep(paste(paste("^", nat_calls, "$", sep = ""), collapse = "|"), dimnames(xc_mat)[[2]])]
str(xc_mat_sub)

# Perform model-based clustering per method
# Don't give the algorithm a set number of clusters, let it find clusters in an unrestricted fashion
method <- c("SPCC", "RF")
mat_list <- list(rf_mat, xc_mat_sub)

# x <- 2
mBIC_res <- rbindlist(invisible(pblapply(1:length(method), function(x){
  
  set.seed(seed)
  mBIC <- mclust::Mclust(data = stats::as.dist(1 - mat_list[[x]], upper = TRUE, diag = TRUE))
  
  if(method[x] == "SPCC"){
     ids <- nat_int_est %>%
       filter(social_scale == "Individual") %>% 
       filter(Bird_ID %in% paste("NAT", nat_indivs, sep = "-")) %>%
       pull(Bird_ID)
  } else {
    ids <- sup_rf_comb_pp %>%
      filter(set == "validatn") %>%
      mutate(
        indiv = as.character(indiv),
        indiv = paste("NAT", indiv, sep = "-")
      ) %>%
      pull(indiv)
  }
 

  mBIC_res <- data.frame(method = method[x], indiv = ids, cluster = as.vector(mBIC$classification))
  
  return(mBIC_res)
  
})))
    
    
mBIC_res

```

A single call was misclassified per method. For SPCC, one RAW call was placed into the same cluster as individual ZW8. For random forests, one call for ZW8 was placed into the same cluster as individual RAW. These results indicated that random forests similarity would not provide a significant advantage when choosing which calls to present and the clusters used to present them in the Shiny app.

# References

    1. Smith-Vidaurre, G., Araya-Salas, M., and T.F. Wright. 2020. Individual signatures outweigh social group identity in contact calls of a communally nesting parrot. Behavioral Ecology 31(2), 448-458. https://doi.org/10.1093/beheco/arz202
    
    2. Smith-Vidaurre, G., Perez-Marrufo, V., & Wright, T. F. 2021. Individual vocal signatures show reduced complexity following invasion. Animal Behavior, 179, 15–39. https://doi.org/10.1016/j.anbehav.2021.06.020
    
```{r chunk17}

sessionInfo()

```